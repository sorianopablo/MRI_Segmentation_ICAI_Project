{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torchsummaryX\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "seed = 1777777\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to save the progress of the trained model on local folders\n",
    "def make_dirs(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "\n",
    "def save_list(name, list):\n",
    "    with open(name, \"wb\") as fp:\n",
    "        pickle.dump(list, fp)\n",
    "\n",
    "def datestr():\n",
    "    now = time.gmtime()\n",
    "    return '{:02}_{:02}___{:02}_{:02}'.format(now.tm_mday, now.tm_mon, now.tm_hour, now.tm_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables of the model:\n",
    "\n",
    "# Path of the folder where the model is going to be saved\n",
    "path = 'saved_models/UNET3D_checkpoints/UNET3D_{}_{}_'.format(datestr(), 'iseg2019')\n",
    "os.makedirs(path)\n",
    "\n",
    "params = {'batch_size': 8,'shuffle': True,'num_workers': 2} # Batch Size\n",
    "samples_train = 10 \n",
    "samples_val = 10\n",
    "split_percent = 0.8 # Split between training and validation\n",
    "total_data = 10 \n",
    "split_idx = int(split_percent * total_data)\n",
    "\n",
    "path='datasets' # Path of the dataset\n",
    "lr = 1e-3 # Learning rate\n",
    "in_channels = 2 # Number of channels (T1 and T2 MRI)\n",
    "num_classes = 4 # Number of classes (White matter, grey matter, background, )\n",
    "weight_decay = 0.0000000001 # Weight decay\n",
    "\n",
    "\n",
    "dict_class_names = {\n",
    "                    \"iseg2019\": [\"Air\", \"CSF\", \"GM\", \"WM\"]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lib.augment3D as augment3D\n",
    "from lib.medloaders import medical_image_process as img_loader\n",
    "from lib.medloaders.medical_loader_utils import get_viz_set, create_sub_volumes\n",
    "\n",
    "\n",
    "class MRIDatasetISEG2019(Dataset):\n",
    "    \"\"\"\n",
    "    Code for reading the infant brain MRI dataset of ISEG 2017 challenge\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode, samples=1000):\n",
    "\n",
    "        root = str(path)\n",
    "\n",
    "        self.mode = mode\n",
    "        self.training_path = root + '/iseg_2019/iSeg-2019-Training/'\n",
    "        self.testing_path = root + '/iseg_2019/iSeg-2019-Validation/'\n",
    "        self.CLASSES = 4\n",
    "        self.full_vol_dim = (144, 192, 256)  # slice, width, height\n",
    "        crop_dim = (128, 128, 128)\n",
    "        self.threshold = 0.00001\n",
    "        self.normalization = 'full_volume_mean'\n",
    "        self.augmentation = True\n",
    "        self.list = []\n",
    "        self.samples = samples_train\n",
    "        self.full_volume = None\n",
    "        self.save_name = root + '/iseg_2019/iseg2019-list-' + mode + '-samples-' + str(samples) + '.txt'\n",
    "        if self.augmentation:\n",
    "            self.transform = augment3D.RandomChoice(\n",
    "                transforms=[augment3D.GaussianNoise(mean=0, std=0.01), augment3D.RandomFlip(),\n",
    "                            augment3D.ElasticTransform()], p=0.5)\n",
    "\n",
    "        subvol = '_vol_' + str(crop_dim[0]) + 'x' + str(crop_dim[1]) + 'x' + str(crop_dim[2])\n",
    "        self.sub_vol_path = root + '/iseg_2019/generated/' + mode + subvol + '/'\n",
    "\n",
    "        make_dirs(self.sub_vol_path)\n",
    "\n",
    "        list_IDsT1 = sorted(glob.glob(os.path.join(self.training_path, '*T1.img')))\n",
    "        list_IDsT2 = sorted(glob.glob(os.path.join(self.training_path, '*T2.img')))\n",
    "        labels = sorted(glob.glob(os.path.join(self.training_path, '*label.img')))\n",
    "        self.affine = img_loader.load_affine_matrix(list_IDsT1[0])\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            list_IDsT1 = list_IDsT1[:split_idx]\n",
    "            list_IDsT2 = list_IDsT2[:split_idx]\n",
    "            labels = labels[:split_idx]\n",
    "            self.list = create_sub_volumes(list_IDsT1, list_IDsT2, labels, dataset_name=\"iseg2019\",\n",
    "                                           mode=mode, samples=samples, full_vol_dim=self.full_vol_dim,\n",
    "                                           crop_size=(128, 128, 64),\n",
    "                                           sub_vol_path=self.sub_vol_path, th_percent=self.threshold)\n",
    "\n",
    "        elif self.mode == 'val':\n",
    "            list_IDsT1 = list_IDsT1[split_idx:]\n",
    "            list_IDsT2 = list_IDsT2[:split_idx:]\n",
    "            labels = labels[split_idx:]\n",
    "            self.list = create_sub_volumes(list_IDsT1, list_IDsT2, labels, dataset_name=\"iseg2019\",\n",
    "                                           mode=mode, samples=samples, full_vol_dim=self.full_vol_dim,\n",
    "                                           crop_size=(128, 128, 64),\n",
    "                                           sub_vol_path=self.sub_vol_path, th_percent=self.threshold)\n",
    "\n",
    "            self.full_volume = get_viz_set(list_IDsT1, list_IDsT2, labels, dataset_name=\"iseg2019\")\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            self.list_IDsT1 = sorted(glob.glob(os.path.join(self.testing_path, '*T1.img')))\n",
    "            self.list_IDsT2 = sorted(glob.glob(os.path.join(self.testing_path, '*T2.img')))\n",
    "            self.labels = None\n",
    "            # todo inference here\n",
    "\n",
    "        save_list(self.save_name, self.list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        t1_path, t2_path, seg_path = self.list[index]\n",
    "        t1, t2, s = np.load(t1_path), np.load(t2_path), np.load(seg_path)\n",
    "        if self.mode == 'train' and self.augmentation:\n",
    "            [augmented_t1, augmented_t2], augmented_s = self.transform([t1, t2], s)\n",
    "\n",
    "            return torch.FloatTensor(augmented_t1.copy()).unsqueeze(0), torch.FloatTensor(\n",
    "                augmented_t2.copy()).unsqueeze(0), torch.FloatTensor(augmented_s.copy())\n",
    "\n",
    "        return torch.FloatTensor(t1).unsqueeze(0), torch.FloatTensor(t2).unsqueeze(0), torch.FloatTensor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: train Subvolume samples to generate:  1000  Volumes:  8\n",
      "Mode: val Subvolume samples to generate:  1000  Volumes:  2\n"
     ]
    }
   ],
   "source": [
    "train_loader = MRIDatasetISEG2019('train')\n",
    "val_loader = MRIDatasetISEG2019('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SAMPLES HAVE BEEN GENERATED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataLoader(train_loader, **params)\n",
    "val_generator = DataLoader(val_loader, **params)\n",
    "\n",
    "print(\"DATA SAMPLES HAVE BEEN GENERATED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module, ABC):\n",
    "    r\"\"\"\n",
    "    BaseModel with basic functionalities for checkpointing and restoration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_loss = 1000000\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        To be implemented by the subclass so that\n",
    "        models can perform a forward propagation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def restore_checkpoint(self, ckpt_file, optimizer=None):\n",
    "        r\"\"\"\n",
    "        Restores checkpoint from a pth file and restores optimizer state.\n",
    "\n",
    "        Args:\n",
    "            ckpt_file (str): A PyTorch pth file containing model weights.\n",
    "            optimizer (Optimizer): A vanilla optimizer to have its state restored from.\n",
    "\n",
    "        Returns:\n",
    "            int: Global step variable where the model was last checkpointed.\n",
    "        \"\"\"\n",
    "        if not ckpt_file:\n",
    "            raise ValueError(\"No checkpoint file to be restored.\")\n",
    "\n",
    "        try:\n",
    "            ckpt_dict = torch.load(ckpt_file)\n",
    "        except RuntimeError:\n",
    "            ckpt_dict = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n",
    "        # Restore model weights\n",
    "        self.load_state_dict(ckpt_dict['model_state_dict'])\n",
    "\n",
    "        # Restore optimizer status if existing. Evaluation doesn't need this\n",
    "        # TODO return optimizer?????\n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(ckpt_dict['optimizer_state_dict'])\n",
    "\n",
    "        # Return global step\n",
    "        return ckpt_dict['epoch']\n",
    "\n",
    "    def save_checkpoint(self,\n",
    "                        directory,\n",
    "                        epoch, loss,\n",
    "                        optimizer=None,\n",
    "                        name=None):\n",
    "        r\"\"\"\n",
    "        Saves checkpoint at a certain global step during training. Optimizer state\n",
    "        is also saved together.\n",
    "\n",
    "        Args:\n",
    "            directory (str): Path to save checkpoint to.\n",
    "            epoch (int): The training. epoch\n",
    "            optimizer (Optimizer): Optimizer state to be saved concurrently.\n",
    "            name (str): The name to save the checkpoint file as.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Create directory to save to\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Build checkpoint dict to save.\n",
    "        ckpt_dict = {\n",
    "            'model_state_dict':\n",
    "                self.state_dict(),\n",
    "            'optimizer_state_dict':\n",
    "                optimizer.state_dict() if optimizer is not None else None,\n",
    "            'epoch':\n",
    "                epoch\n",
    "        }\n",
    "\n",
    "        # Save the file with specific name\n",
    "        if name is None:\n",
    "            name = \"{}_{}_epoch.pth\".format(\n",
    "                os.path.basename(directory),  # netD or netG\n",
    "                'last')\n",
    "\n",
    "        torch.save(ckpt_dict, os.path.join(directory, name))\n",
    "        if self.best_loss > loss:\n",
    "            self.best_loss = loss\n",
    "            name = \"{}_BEST.pth\".format(\n",
    "                os.path.basename(directory))\n",
    "            torch.save(ckpt_dict, os.path.join(directory, name))\n",
    "\n",
    "    def count_params(self):\n",
    "        r\"\"\"\n",
    "        Computes the number of parameters in this model.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            int: Total number of weight parameters for this model.\n",
    "            int: Total number of trainable parameters for this model.\n",
    "\n",
    "        \"\"\"\n",
    "        num_total_params = sum(p.numel() for p in self.parameters())\n",
    "        num_trainable_params = sum(p.numel() for p in self.parameters()\n",
    "                                   if p.requires_grad)\n",
    "\n",
    "        return num_total_params, num_trainable_params\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                output = output[0]\n",
    "            return output.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(BaseModel):\n",
    "    \"\"\"\n",
    "    Implementations based on the Unet3D paper: https://arxiv.org/abs/1606.06650\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, n_classes, base_n_filter=8):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.base_n_filter = base_n_filter\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.dropout3d = nn.Dropout3d(p=0.6)\n",
    "        self.upsacle = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.conv3d_c1_1 = nn.Conv3d(self.in_channels, self.base_n_filter, kernel_size=3, stride=1, padding=1,\n",
    "                                     bias=False)\n",
    "        self.conv3d_c1_2 = nn.Conv3d(self.base_n_filter, self.base_n_filter, kernel_size=3, stride=1, padding=1,\n",
    "                                     bias=False)\n",
    "        self.lrelu_conv_c1 = self.lrelu_conv(self.base_n_filter, self.base_n_filter)\n",
    "        self.inorm3d_c1 = nn.InstanceNorm3d(self.base_n_filter)\n",
    "\n",
    "        self.conv3d_c2 = nn.Conv3d(self.base_n_filter, self.base_n_filter * 2, kernel_size=3, stride=2, padding=1,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_conv_c2 = self.norm_lrelu_conv(self.base_n_filter * 2, self.base_n_filter * 2)\n",
    "        self.inorm3d_c2 = nn.InstanceNorm3d(self.base_n_filter * 2)\n",
    "\n",
    "        self.conv3d_c3 = nn.Conv3d(self.base_n_filter * 2, self.base_n_filter * 4, kernel_size=3, stride=2, padding=1,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_conv_c3 = self.norm_lrelu_conv(self.base_n_filter * 4, self.base_n_filter * 4)\n",
    "        self.inorm3d_c3 = nn.InstanceNorm3d(self.base_n_filter * 4)\n",
    "\n",
    "        self.conv3d_c4 = nn.Conv3d(self.base_n_filter * 4, self.base_n_filter * 8, kernel_size=3, stride=2, padding=1,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_conv_c4 = self.norm_lrelu_conv(self.base_n_filter * 8, self.base_n_filter * 8)\n",
    "        self.inorm3d_c4 = nn.InstanceNorm3d(self.base_n_filter * 8)\n",
    "\n",
    "        self.conv3d_c5 = nn.Conv3d(self.base_n_filter * 8, self.base_n_filter * 16, kernel_size=3, stride=2, padding=1,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_conv_c5 = self.norm_lrelu_conv(self.base_n_filter * 16, self.base_n_filter * 16)\n",
    "        self.norm_lrelu_upscale_conv_norm_lrelu_l0 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter * 16,\n",
    "                                                                                             self.base_n_filter * 8)\n",
    "\n",
    "        self.conv3d_l0 = nn.Conv3d(self.base_n_filter * 8, self.base_n_filter * 8, kernel_size=1, stride=1, padding=0,\n",
    "                                   bias=False)\n",
    "        self.inorm3d_l0 = nn.InstanceNorm3d(self.base_n_filter * 8)\n",
    "\n",
    "        self.conv_norm_lrelu_l1 = self.conv_norm_lrelu(self.base_n_filter * 16, self.base_n_filter * 16)\n",
    "        self.conv3d_l1 = nn.Conv3d(self.base_n_filter * 16, self.base_n_filter * 8, kernel_size=1, stride=1, padding=0,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_upscale_conv_norm_lrelu_l1 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter * 8,\n",
    "                                                                                             self.base_n_filter * 4)\n",
    "\n",
    "        self.conv_norm_lrelu_l2 = self.conv_norm_lrelu(self.base_n_filter * 8, self.base_n_filter * 8)\n",
    "        self.conv3d_l2 = nn.Conv3d(self.base_n_filter * 8, self.base_n_filter * 4, kernel_size=1, stride=1, padding=0,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_upscale_conv_norm_lrelu_l2 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter * 4,\n",
    "                                                                                             self.base_n_filter * 2)\n",
    "\n",
    "        self.conv_norm_lrelu_l3 = self.conv_norm_lrelu(self.base_n_filter * 4, self.base_n_filter * 4)\n",
    "        self.conv3d_l3 = nn.Conv3d(self.base_n_filter * 4, self.base_n_filter * 2, kernel_size=1, stride=1, padding=0,\n",
    "                                   bias=False)\n",
    "        self.norm_lrelu_upscale_conv_norm_lrelu_l3 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter * 2,\n",
    "                                                                                             self.base_n_filter)\n",
    "\n",
    "        self.conv_norm_lrelu_l4 = self.conv_norm_lrelu(self.base_n_filter * 2, self.base_n_filter * 2)\n",
    "        self.conv3d_l4 = nn.Conv3d(self.base_n_filter * 2, self.n_classes, kernel_size=1, stride=1, padding=0,\n",
    "                                   bias=False)\n",
    "\n",
    "        self.ds2_1x1_conv3d = nn.Conv3d(self.base_n_filter * 8, self.n_classes, kernel_size=1, stride=1, padding=0,\n",
    "                                        bias=False)\n",
    "        self.ds3_1x1_conv3d = nn.Conv3d(self.base_n_filter * 4, self.n_classes, kernel_size=1, stride=1, padding=0,\n",
    "                                        bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def conv_norm_lrelu(self, feat_in, feat_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm3d(feat_out),\n",
    "            nn.LeakyReLU())\n",
    "\n",
    "    def norm_lrelu_conv(self, feat_in, feat_out):\n",
    "        return nn.Sequential(\n",
    "            nn.InstanceNorm3d(feat_in),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "\n",
    "    def lrelu_conv(self, feat_in, feat_out):\n",
    "        return nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "\n",
    "    def norm_lrelu_upscale_conv_norm_lrelu(self, feat_in, feat_out):\n",
    "        return nn.Sequential(\n",
    "            nn.InstanceNorm3d(feat_in),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            # should be feat_in*2 or feat_in\n",
    "            nn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm3d(feat_out),\n",
    "            nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        #  Level 1 context pathway\n",
    "        out = self.conv3d_c1_1(x)\n",
    "        residual_1 = out\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv3d_c1_2(out)\n",
    "        out = self.dropout3d(out)\n",
    "        out = self.lrelu_conv_c1(out)\n",
    "        # Element Wise Summation\n",
    "        out += residual_1\n",
    "        context_1 = self.lrelu(out)\n",
    "        out = self.inorm3d_c1(out)\n",
    "        out = self.lrelu(out)\n",
    "\n",
    "        # Level 2 context pathway\n",
    "        out = self.conv3d_c2(out)\n",
    "        residual_2 = out\n",
    "        out = self.norm_lrelu_conv_c2(out)\n",
    "        out = self.dropout3d(out)\n",
    "        out = self.norm_lrelu_conv_c2(out)\n",
    "        out += residual_2\n",
    "        out = self.inorm3d_c2(out)\n",
    "        out = self.lrelu(out)\n",
    "        context_2 = out\n",
    "\n",
    "        # Level 3 context pathway\n",
    "        out = self.conv3d_c3(out)\n",
    "        residual_3 = out\n",
    "        out = self.norm_lrelu_conv_c3(out)\n",
    "        out = self.dropout3d(out)\n",
    "        out = self.norm_lrelu_conv_c3(out)\n",
    "        out += residual_3\n",
    "        out = self.inorm3d_c3(out)\n",
    "        out = self.lrelu(out)\n",
    "        context_3 = out\n",
    "\n",
    "        # Level 4 context pathway\n",
    "        out = self.conv3d_c4(out)\n",
    "        residual_4 = out\n",
    "        out = self.norm_lrelu_conv_c4(out)\n",
    "        out = self.dropout3d(out)\n",
    "        out = self.norm_lrelu_conv_c4(out)\n",
    "        out += residual_4\n",
    "        out = self.inorm3d_c4(out)\n",
    "        out = self.lrelu(out)\n",
    "        context_4 = out\n",
    "\n",
    "        # Level 5\n",
    "        out = self.conv3d_c5(out)\n",
    "        residual_5 = out\n",
    "        out = self.norm_lrelu_conv_c5(out)\n",
    "        out = self.dropout3d(out)\n",
    "        out = self.norm_lrelu_conv_c5(out)\n",
    "        out += residual_5\n",
    "        out = self.norm_lrelu_upscale_conv_norm_lrelu_l0(out)\n",
    "\n",
    "        out = self.conv3d_l0(out)\n",
    "        out = self.inorm3d_l0(out)\n",
    "        out = self.lrelu(out)\n",
    "\n",
    "        # Level 1 localization pathway\n",
    "        out = torch.cat([out, context_4], dim=1)\n",
    "        out = self.conv_norm_lrelu_l1(out)\n",
    "        out = self.conv3d_l1(out)\n",
    "        out = self.norm_lrelu_upscale_conv_norm_lrelu_l1(out)\n",
    "\n",
    "        # Level 2 localization pathway\n",
    "        # print(out.shape)\n",
    "        # print(context_3.shape)\n",
    "        out = torch.cat([out, context_3], dim=1)\n",
    "        out = self.conv_norm_lrelu_l2(out)\n",
    "        ds2 = out\n",
    "        out = self.conv3d_l2(out)\n",
    "        out = self.norm_lrelu_upscale_conv_norm_lrelu_l2(out)\n",
    "\n",
    "        # Level 3 localization pathway\n",
    "        out = torch.cat([out, context_2], dim=1)\n",
    "        out = self.conv_norm_lrelu_l3(out)\n",
    "        ds3 = out\n",
    "        out = self.conv3d_l3(out)\n",
    "        out = self.norm_lrelu_upscale_conv_norm_lrelu_l3(out)\n",
    "\n",
    "        # Level 4 localization pathway\n",
    "        out = torch.cat([out, context_1], dim=1)\n",
    "        out = self.conv_norm_lrelu_l4(out)\n",
    "        out_pred = self.conv3d_l4(out)\n",
    "\n",
    "        ds2_1x1_conv = self.ds2_1x1_conv3d(ds2)\n",
    "        ds1_ds2_sum_upscale = self.upsacle(ds2_1x1_conv)\n",
    "        ds3_1x1_conv = self.ds3_1x1_conv3d(ds3)\n",
    "        ds1_ds2_sum_upscale_ds3_sum = ds1_ds2_sum_upscale + ds3_1x1_conv\n",
    "        ds1_ds2_sum_upscale_ds3_sum_upscale = self.upsacle(ds1_ds2_sum_upscale_ds3_sum)\n",
    "\n",
    "        out = out_pred + ds1_ds2_sum_upscale_ds3_sum_upscale\n",
    "        seg_layer = out\n",
    "        return seg_layer\n",
    "\n",
    "    def test(self,device='cpu'):\n",
    "\n",
    "        input_tensor = torch.rand(1, 2, 32, 32, 32)\n",
    "        ideal_out = torch.rand(1, self.n_classes, 32, 32, 32)\n",
    "        out = self.forward(input_tensor)\n",
    "        assert ideal_out.shape == out.shape\n",
    "        summary(self.to(torch.device(device)), (2, 32, 32, 32),device='cpu')\n",
    "        # import torchsummaryX\n",
    "        # torchsummaryX.summary(self, input_tensor.to(device))\n",
    "        print(\"Unet3D test is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model . . . . . . . .UNET3D\n",
      "UNET3D Number of params: 1781744\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Model . . . . . . . .\" + 'UNET3D')\n",
    "\n",
    "model = UNet3D(in_channels=in_channels, n_classes=num_classes, base_n_filter=8)\n",
    "\n",
    "print('UNET3D', 'Number of params: {}'.format(\n",
    "    sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_channel_dice(input, target, epsilon=1e-6, weight=None):\n",
    "    \"\"\"\n",
    "    Computes DiceCoefficient as defined in https://arxiv.org/abs/1606.04797 given  a multi channel input and target.\n",
    "    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.\n",
    "\n",
    "    Args:\n",
    "         input (torch.Tensor): NxCxSpatial input tensor\n",
    "         target (torch.Tensor): NxCxSpatial target tensor\n",
    "         epsilon (float): prevents division by zero\n",
    "         weight (torch.Tensor): Cx1 tensor of weight per channel/class\n",
    "    \"\"\"\n",
    "\n",
    "    # input and target shapes must match\n",
    "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "\n",
    "    def flatten(tensor):\n",
    "        \"\"\"Flattens a given tensor such that the channel axis is first.\n",
    "        The shapes are transformed as follows:\n",
    "        (N, C, D, H, W) -> (C, N * D * H * W)\n",
    "        \"\"\"\n",
    "        # number of channels\n",
    "        C = tensor.size(1)\n",
    "        # new axis order\n",
    "        axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
    "        # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
    "        transposed = tensor.permute(axis_order)\n",
    "        # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
    "        return transposed.contiguous().view(C, -1)\n",
    "\n",
    "    input = flatten(input)\n",
    "    target = flatten(target)\n",
    "    target = target.float()\n",
    "\n",
    "    # compute per channel Dice Coefficient\n",
    "    intersect = (input * target).sum(-1)\n",
    "    if weight is not None:\n",
    "        intersect = weight * intersect\n",
    "\n",
    "    # here we can use standard dice (input + target).sum(-1) or extension (see V-Net) (input^2 + target^2).sum(-1)\n",
    "    denominator = (input * input).sum(-1) + (target * target).sum(-1)\n",
    "    return 2 * (intersect / denominator.clamp(min=epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AbstractDiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for different implementations of Dice loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight=None, sigmoid_normalization=True):\n",
    "        super(_AbstractDiceLoss, self).__init__()\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.classes = None\n",
    "        self.skip_index_after = None\n",
    "        # The output from the network during training is assumed to be un-normalized probabilities and we would\n",
    "        # like to normalize the logits. Since Dice (or soft Dice in this case) is usually used for binary data,\n",
    "        # normalizing the channels with Sigmoid is the default choice even for multi-class segmentation problems.\n",
    "        # However if one would like to apply Softmax in order to get the proper probability distribution from the\n",
    "        # output, just specify sigmoid_normalization=False.\n",
    "        if sigmoid_normalization:\n",
    "            self.normalization = nn.Sigmoid()\n",
    "        else:\n",
    "            self.normalization = nn.Softmax(dim=1)\n",
    "\n",
    "    def expand_as_one_hot(input, C, ignore_index=None):\n",
    "        if input.dim() == 5:\n",
    "            return input\n",
    "        assert input.dim() == 4\n",
    "\n",
    "        # expand the input tensor to Nx1xDxHxW before scattering\n",
    "        input = input.unsqueeze(1)\n",
    "        # create result tensor shape (NxCxDxHxW)\n",
    "        shape = list(input.size())\n",
    "        shape[1] = C\n",
    "\n",
    "        if ignore_index is not None:\n",
    "            # create ignore_index mask for the result\n",
    "            mask = input.expand(shape) == ignore_index\n",
    "            # clone the lib tensor and zero out ignore_index in the input\n",
    "            input = input.clone()\n",
    "            input[input == ignore_index] = 0\n",
    "            # scatter to get the one-hot tensor\n",
    "            result = torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
    "            # bring back the ignore_index in the result\n",
    "            result[mask] = ignore_index\n",
    "            return result\n",
    "        else:\n",
    "            # scatter to get the one-hot tensor\n",
    "            return torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
    "\n",
    "    def dice(self, input, target, weight):\n",
    "        # actual Dice score computation; to be implemented by the subclass\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def skip_target_channels(self, target, index):\n",
    "        \"\"\"\n",
    "        Assuming dim 1 is the classes dim , it skips all the indexes after the desired class\n",
    "        \"\"\"\n",
    "        assert index >= 2\n",
    "        return target[:, 0:index, ...]\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \"\"\"\n",
    "        Expand to one hot added extra for consistency reasons\n",
    "        \"\"\"\n",
    "        target = expand_as_one_hot(target.long(), self.classes)\n",
    "\n",
    "        assert input.dim() == target.dim() == 5, \"'input' and 'target' have different number of dims\"\n",
    "\n",
    "        if self.skip_index_after is not None:\n",
    "            before_size = target.size()\n",
    "            target = self.skip_target_channels(target, self.skip_index_after)\n",
    "            print(\"Target {} after skip index {}\".format(before_size, target.size()))\n",
    "\n",
    "        assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "        # get probabilities from logits\n",
    "        input = self.normalization(input)\n",
    "\n",
    "        # compute per channel Dice coefficient\n",
    "        per_channel_dice = self.dice(input, target, weight=self.weight)\n",
    "\n",
    "        loss = (1. - torch.mean(per_channel_dice))\n",
    "        per_channel_dice = per_channel_dice.detach().cpu().numpy()\n",
    "\n",
    "        # average Dice score across all channels/classes\n",
    "        return loss, per_channel_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(_AbstractDiceLoss):\n",
    "    \"\"\"Computes Dice Loss according to https://arxiv.org/abs/1606.04797.\n",
    "    For multi-class segmentation `weight` parameter can be used to assign different weights per class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes=4, skip_index_after=None, weight=None, sigmoid_normalization=True ):\n",
    "        super().__init__(weight, sigmoid_normalization)\n",
    "        self.classes = classes\n",
    "        if skip_index_after is not None:\n",
    "            self.skip_index_after = skip_index_after\n",
    "\n",
    "    def dice(self, input, target, weight):\n",
    "        return compute_per_channel_dice(input, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss(classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(input_tuple, inModalities=-1, inChannels=-1, cuda=False, args=None):\n",
    "    if args is not None:\n",
    "        modalities = args.inModalities\n",
    "        channels = args.inChannels\n",
    "        in_cuda = args.cuda\n",
    "    else:\n",
    "        modalities = inModalities\n",
    "        channels = inChannels\n",
    "        in_cuda = cuda\n",
    "    if modalities == 4:\n",
    "        if channels == 4:\n",
    "            img_1, img_2, img_3, img_4, target = input_tuple\n",
    "            input_tensor = torch.cat((img_1, img_2, img_3, img_4), dim=1)\n",
    "        elif channels == 3:\n",
    "            # t1 post constast is ommited\n",
    "            img_1, _, img_3, img_4, target = input_tuple\n",
    "            input_tensor = torch.cat((img_1, img_3, img_4), dim=1)\n",
    "        elif channels == 2:\n",
    "            # t1 and t2 only\n",
    "            img_1, _, img_3, _, target = input_tuple\n",
    "            input_tensor = torch.cat((img_1, img_3), dim=1)\n",
    "        elif channels == 1:\n",
    "            # t1 only\n",
    "            input_tensor, _, _, target = input_tuple\n",
    "    if modalities == 3:\n",
    "        if channels == 3:\n",
    "            img_1, img_2, img_3, target = input_tuple\n",
    "            input_tensor = torch.cat((img_1, img_2, img_3), dim=1)\n",
    "        elif channels == 2:\n",
    "            img_1, img_2, _, target = input_tuple\n",
    "            input_tensor = torch.cat((img_1, img_2), dim=1)\n",
    "        elif channels == 1:\n",
    "            input_tensor, _, _, target = input_tuple\n",
    "    elif modalities == 2:\n",
    "        if channels == 2:\n",
    "            img_t1, img_t2, target = input_tuple\n",
    "\n",
    "            input_tensor = torch.cat((img_t1, img_t2), dim=1)\n",
    "\n",
    "        elif channels == 1:\n",
    "            input_tensor, _, target = input_tuple\n",
    "    elif modalities == 1:\n",
    "        input_tensor, target = input_tuple\n",
    "\n",
    "    if in_cuda:\n",
    "        input_tensor, target = input_tensor.cuda(), target.cuda()\n",
    "\n",
    "    return input_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorboardWriter():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        name_model = 'saved_models_/UNET3D_checkpoints/UNET3D_{}_{}_'.format(datestr(), 'iseg2019')\n",
    "        self.writer = SummaryWriter(log_dir='saved_models_' + name_model, comment=name_model)\n",
    "        make_dirs(name_model)\n",
    "        self.csv_train, self.csv_val = self.create_stats_files(name_model)\n",
    "        self.dataset_name = 'iseg2019'\n",
    "        self.classes = 4\n",
    "        self.label_names = dict_class_names['iseg2019']\n",
    "\n",
    "        self.data = self.create_data_structure()\n",
    "\n",
    "    def create_data_structure(self, ):\n",
    "        data = {\"train\": dict((label, 0.0) for label in self.label_names),\n",
    "                \"val\": dict((label, 0.0) for label in self.label_names)}\n",
    "        data['train']['loss'] = 0.0\n",
    "        data['val']['loss'] = 0.0\n",
    "        data['train']['count'] = 1.0\n",
    "        data['val']['count'] = 1.0\n",
    "        data['train']['dsc'] = 0.0\n",
    "        data['val']['dsc'] = 0.0\n",
    "        return data\n",
    "\n",
    "    def display_terminal(self, iter, epoch, mode='train', summary=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :param iter: iteration or partial epoch\n",
    "        :param epoch: epoch of training\n",
    "        :param loss: any loss numpy\n",
    "        :param mode: train or val ( for training and validation)\n",
    "        :param summary: to print total statistics at the end of epoch\n",
    "        \"\"\"\n",
    "        if summary:\n",
    "            info_print = \"\\nSummary {} Epoch {:2d}:  Loss:{:.4f} \\t DSC:{:.4f}  \".format(mode, epoch,\n",
    "                                                                                         self.data[mode]['loss'] /\n",
    "                                                                                         self.data[mode]['count'],\n",
    "                                                                                         self.data[mode]['dsc'] /\n",
    "                                                                                         self.data[mode]['count'])\n",
    "\n",
    "            for i in range(len(self.label_names)):\n",
    "                info_print += \"\\t{} : {:.4f}\".format(self.label_names[i],\n",
    "                                                     self.data[mode][self.label_names[i]] / self.data[mode]['count'])\n",
    "\n",
    "            print(info_print)\n",
    "        else:\n",
    "\n",
    "            info_print = \"\\nEpoch: {:.2f} Loss:{:.4f} \\t DSC:{:.4f}\".format(iter, self.data[mode]['loss'] /\n",
    "                                                                            self.data[mode]['count'],\n",
    "                                                                            self.data[mode]['dsc'] /\n",
    "                                                                            self.data[mode]['count'])\n",
    "\n",
    "            for i in range(len(self.label_names)):\n",
    "                info_print += \"\\t{}:{:.4f}\".format(self.label_names[i],\n",
    "                                                   self.data[mode][self.label_names[i]] / self.data[mode]['count'])\n",
    "            print(info_print)\n",
    "\n",
    "    def create_stats_files(self, path):\n",
    "        train_f = open(os.path.join(path, 'train.csv'), 'w')\n",
    "        val_f = open(os.path.join(path, 'val.csv'), 'w')\n",
    "        return train_f, val_f\n",
    "\n",
    "    def reset(self, mode):\n",
    "        self.data[mode]['dsc'] = 0.0\n",
    "        self.data[mode]['loss'] = 0.0\n",
    "        self.data[mode]['count'] = 1\n",
    "        for i in range(len(self.label_names)):\n",
    "            self.data[mode][self.label_names[i]] = 0.0\n",
    "\n",
    "    def update_scores(self, iter, loss, channel_score, mode, writer_step):\n",
    "        \"\"\"\n",
    "        :param iter: iteration or partial epoch\n",
    "        :param loss: any loss torch.tensor.item()\n",
    "        :param channel_score: per channel score or dice coef\n",
    "        :param mode: train or val ( for training and validation)\n",
    "        :param writer_step: tensorboard writer step\n",
    "        \"\"\"\n",
    "        # WARNING ASSUMING THAT CHANNELS IN SAME ORDER AS DICTIONARY\n",
    "\n",
    "        dice_coeff = np.mean(channel_score) * 100\n",
    "\n",
    "        num_channels = len(channel_score)\n",
    "        self.data[mode]['dsc'] += dice_coeff\n",
    "        self.data[mode]['loss'] += loss\n",
    "        self.data[mode]['count'] = iter + 1\n",
    "\n",
    "        for i in range(num_channels):\n",
    "            self.data[mode][self.label_names[i]] += channel_score[i]\n",
    "            if self.writer is not None:\n",
    "                self.writer.add_scalar(mode + '/' + self.label_names[i], channel_score[i], global_step=writer_step)\n",
    "\n",
    "    def write_end_of_epoch(self, epoch):\n",
    "\n",
    "        self.writer.add_scalars('DSC/', {'train': self.data['train']['dsc'] / self.data['train']['count'],\n",
    "                                         'val': self.data['val']['dsc'] / self.data['val']['count'],\n",
    "                                         }, epoch)\n",
    "        self.writer.add_scalars('Loss/', {'train': self.data['train']['loss'] / self.data['train']['count'],\n",
    "                                          'val': self.data['val']['loss'] / self.data['val']['count'],\n",
    "                                          }, epoch)\n",
    "        for i in range(len(self.label_names)):\n",
    "            self.writer.add_scalars(self.label_names[i],\n",
    "                                    {'train': self.data['train'][self.label_names[i]] / self.data['train']['count'],\n",
    "                                     'val': self.data['val'][self.label_names[i]] / self.data['train']['count'],\n",
    "                                     }, epoch)\n",
    "\n",
    "        train_csv_line = 'Epoch:{:2d} Loss:{:.4f} DSC:{:.4f}'.format(epoch,\n",
    "                                                                     self.data['train']['loss'] / self.data['train'][\n",
    "                                                                         'count'],\n",
    "                                                                     self.data['train']['dsc'] / self.data['train'][\n",
    "                                                                         'count'])\n",
    "        val_csv_line = 'Epoch:{:2d} Loss:{:.4f} DSC:{:.4f}'.format(epoch,\n",
    "                                                                   self.data['val']['loss'] / self.data['val'][\n",
    "                                                                       'count'],\n",
    "                                                                   self.data['val']['dsc'] / self.data['val'][\n",
    "                                                                       'count'])\n",
    "        self.csv_train.write(train_csv_line + '\\n')\n",
    "        self.csv_val.write(val_csv_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Trainer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, criterion, optimizer, train_data_loader,\n",
    "                 valid_data_loader=None, lr_scheduler=None):\n",
    "\n",
    "    \n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.train_data_loader = train_data_loader\n",
    "        # epoch-based training\n",
    "        self.len_epoch = len(self.train_data_loader)\n",
    "        self.valid_data_loader = valid_data_loader\n",
    "        self.do_validation = self.valid_data_loader is not None\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.log_step = int(np.sqrt(train_data_loader.batch_size))\n",
    "        self.writer = TensorboardWriter()\n",
    "\n",
    "        self.save_frequency = 10\n",
    "        self.terminal_show_freq = 50\n",
    "        self.start_epoch = 1\n",
    "\n",
    "    def training(self):\n",
    "        for epoch in range(self.start_epoch, 200):\n",
    "            self.train_epoch(epoch)\n",
    "\n",
    "            if self.do_validation:\n",
    "                self.validate_epoch(epoch)\n",
    "\n",
    "            val_loss = self.writer.data['val']['loss'] / self.writer.data['val']['count']\n",
    "\n",
    "            if ((epoch + 1) % self.save_frequency):\n",
    "                self.model.save_checkpoint('saved_models/UNET3D_checkpoints/UNET3D_{}_{}_'.format(datestr(), 'iseg2019'),\n",
    "                                           epoch, val_loss,\n",
    "                                           optimizer=self.optimizer)\n",
    "\n",
    "            self.writer.write_end_of_epoch(epoch)\n",
    "\n",
    "            self.writer.reset('train')\n",
    "            self.writer.reset('val')\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        for batch_idx, input_tuple in enumerate(self.train_data_loader):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            input_tensor, target = prepare_input(input_tuple=input_tuple, args=self.args)\n",
    "            input_tensor.requires_grad = True\n",
    "            output = self.model(input_tensor)\n",
    "            loss_dice, per_ch_score = self.criterion(output, target)\n",
    "            loss_dice.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.writer.update_scores(batch_idx, loss_dice.item(), per_ch_score, 'train',\n",
    "                                      epoch * self.len_epoch + batch_idx)\n",
    "\n",
    "            if (batch_idx + 1) % self.terminal_show_freq == 0:\n",
    "                partial_epoch = epoch + batch_idx / self.len_epoch - 1\n",
    "                self.writer.display_terminal(partial_epoch, epoch, 'train')\n",
    "\n",
    "        self.writer.display_terminal(self.len_epoch, epoch, mode='train', summary=True)\n",
    "\n",
    "    def validate_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch_idx, input_tuple in enumerate(self.valid_data_loader):\n",
    "            with torch.no_grad():\n",
    "                input_tensor, target = prepare_input(input_tuple=input_tuple, args=self.args)\n",
    "                input_tensor.requires_grad = False\n",
    "\n",
    "                output = self.model(input_tensor)\n",
    "                loss, per_ch_score = self.criterion(output, target)\n",
    "\n",
    "                self.writer.update_scores(batch_idx, loss.item(), per_ch_score, 'val',\n",
    "                                          epoch * self.len_epoch + batch_idx)\n",
    "\n",
    "        self.writer.display_terminal(len(self.valid_data_loader), epoch, mode='val', summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, criterion, optimizer, train_data_loader=training_generator,\n",
    "                        valid_data_loader=val_generator, lr_scheduler=None)\n",
    "print(\"START TRAINING...\")\n",
    "trainer.training()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3003d60037c18bfdc7b2bf1f88978c84f5300bd3c30584e823ef4af01354ff6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('3d_segm_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
